<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NanoLogic - EE6350 Spring 2025</title>
  <style>
    * {margin: 0; padding: 0; box-sizing: border-box;}
    
    :root {
      --primary: #1e3a5f;
      --primary-light: #2c5282;
      --accent: #5d9cec;
      --accent-light: #8ebaf5;
      --columbia-blue: #b3d9ff;
      --bg-light: #f8fafc;
      --text-dark: #1a202c;
      --text-gray: #4a5568;
      --border: #e2e8f0;
    }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      margin: 0;
      background: #f7f9fc;
      color: var(--text-dark);
      line-height: 1.7;
    }
    
    /* Header with gradient and modern design */
    header {
      background: linear-gradient(135deg, #5d9cec 0%, #7db3f5 50%, #9ec9f8 100%);
      color: #ffffff;
      padding: 0;
      position: relative;
      overflow: hidden;
    }
    
    /* Decorative background pattern */
    header::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: 
        radial-gradient(circle at 20% 50%, rgba(255, 255, 255, 0.15) 0%, transparent 50%),
        radial-gradient(circle at 80% 80%, rgba(255, 255, 255, 0.1) 0%, transparent 50%);
      pointer-events: none;
    }
    
    .header-content {
      position: relative;
      max-width: 1200px;
      margin: 0 auto;
      padding: 40px 40px 30px;
      text-align: center;
      z-index: 1;
    }
    
    /* Project type badge */
    .project-badge {
      display: inline-block;
      background: rgba(255, 255, 255, 0.25);
      color: #ffffff;
      padding: 6px 18px;
      border-radius: 20px;
      font-size: 0.8em;
      font-weight: 600;
      letter-spacing: 1px;
      text-transform: uppercase;
      margin-bottom: 16px;
      border: 1px solid rgba(255, 255, 255, 0.3);
    }
    
    header h1 {
      font-size: 3.2em;
      font-weight: 600;
      letter-spacing: -0.5px;
      margin-bottom: 8px;
      color: #ffffff;
      text-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    

    
    .header-meta {
      display: flex;
      justify-content: center;
      gap: 20px;
      flex-wrap: wrap;
      margin-top: 10px;
      font-size: 0.9em;
      opacity: 0.9;
    }
    
    .header-meta-item {
      display: flex;
      align-items: center;
      gap: 6px;
    }
    
    .header-meta-item::before {
      content: '●';
      color: rgba(255, 255, 255, 0.6);
    }
    
    /* Author Info */
    .author-info {
      margin-top: 12px;
      padding-top: 12px;
      border-top: 1px solid rgba(255, 255, 255, 0.2);
    }
    
    .authors-list {
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 12px;
    }
    
    .author-name {
      font-size: 1em;
      font-weight: 500;
      color: rgba(255, 255, 255, 0.95);
      text-decoration: none;
      padding: 6px 16px;
      border-radius: 6px;
      background: rgba(255, 255, 255, 0.12);
      transition: all 0.2s ease;
      border: 1px solid rgba(255, 255, 255, 0.2);
      display: inline-block;
    }
    
    .author-name:hover {
      background: rgba(255, 255, 255, 0.2);
      border-color: rgba(255, 255, 255, 0.35);
      transform: translateY(-1px);
    }
    
    /* Navigation - sleek and modern */
    .nav-buttons {
      background: rgba(255,255,255,0.95);
      backdrop-filter: blur(10px);
      padding: 0;
      position: sticky;
      top: 0;
      z-index: 100;
      box-shadow: 0 2px 8px rgba(0,0,0,0.06);
      border-bottom: 1px solid var(--border);
    }
    
    .nav-container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 10px 40px;
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 4px;
    }
    
    .nav-buttons a {
      display: inline-block;
      color: var(--text-dark);
      padding: 8px 18px;
      border-radius: 6px;
      text-decoration: none;
      font-size: 0.9em;
      font-weight: 500;
      transition: all 0.2s ease;
      position: relative;
    }
    
    .nav-buttons a:hover {
      color: var(--accent);
      background: var(--bg-light);
    }
    
    /* Container */
    .container {
      max-width: 1000px;
      margin: 50px auto;
      padding: 60px 50px;
      background: #ffffff;
      border-radius: 16px;
      box-shadow: 0 4px 24px rgba(0,0,0,0.06);
    }
    
    /* Back Link */
    .back {
      display: inline-flex;
      align-items: center;
      margin-bottom: 40px;
      color: var(--accent);
      text-decoration: none;
      font-weight: 600;
      font-size: 0.95em;
      padding: 10px 18px;
      border-radius: 8px;
      transition: all 0.3s ease;
      border: 1px solid transparent;
    }
    
    .back:hover {
      background: var(--bg-light);
      border-color: var(--accent);
      transform: translateX(-4px);
    }
    
    .back::before {
      content: '←';
      margin-right: 8px;
      font-size: 1.3em;
      transition: transform 0.3s ease;
    }
    
    .back:hover::before {
      transform: translateX(-4px);
    }
    
    /* Sections */
    section {
      scroll-margin-top: 100px;
      margin-bottom: 70px;
      padding-bottom: 50px;
      border-bottom: 2px solid var(--bg-light);
    }
    
    section:last-of-type {
      border-bottom: none;
    }
    
    h2 {
      color: var(--primary);
      font-size: 2.2em;
      font-weight: 600;
      margin-bottom: 24px;
      position: relative;
      padding-bottom: 16px;
    }
    
    h2::after {
      content: '';
      position: absolute;
      bottom: 0;
      left: 0;
      width: 50px;
      height: 3px;
      background: var(--accent);
      border-radius: 2px;
    }
    
    h3 {
      color: var(--primary-light);
      font-size: 1.5em;
      font-weight: 600;
      margin-top: 36px;
      margin-bottom: 16px;
    }
    
    .instruction-text {
      background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
      border-left: 4px solid #5d9cec;
      padding: 16px 20px;
      margin: 20px 0;
      border-radius: 8px;
      color: #1e3a5f;
      font-size: 0.95em;
      font-style: italic;
    }
    
    p {
      color: #4a5568;
      font-size: 1.05em;
      line-height: 1.8;
      margin-bottom: 16px;
    }
    
    /* Images */
    .image-placeholder {
      width: 100%;
      height: 400px;
      background: linear-gradient(135deg, var(--bg-light) 0%, #e2e8f0 100%);
      border-radius: 12px;
      margin: 24px 0;
      display: flex;
      align-items: center;
      justify-content: center;
      border: 2px dashed var(--border);
      color: var(--text-light);
      font-size: 1.1em;
      font-weight: 500;
    }
    
    img {
      max-width: 100%;
      max-height: 100%;
      height: auto;
      border-radius: 12px;
      margin: 24px 0;
      box-shadow: 0 8px 24px rgba(0,0,0,0.12);
      border: 1px solid var(--border);
    }

    .caption {
      text-align: center;
      font-size: 0.9em;
      color: var(--text-gray);
      margin-top: -10px;
    }



h4 {
  font-size: 1.3em;
  font-weight: 600;
  color: var(--primary-light);
  margin-top: 32px;
  margin-bottom: 20px;
  padding-left: 12px;
  border-left: 4px solid var(--primary-light);
  position: relative;
  letter-spacing: 0.3px;
}





    
    /* Video */
    .video-container {
      position: relative;
      padding-bottom: 56.25%;
      height: 0;
      overflow: hidden;
      border-radius: 12px;
      margin: 24px 0;
      box-shadow: 0 8px 24px rgba(0,0,0,0.12);
      border: 1px solid var(--border);
    }
    
    .video-container iframe {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border: none;
    }
    
    /* Specs Table */
    .specs-table {
      width: 100%;
      border-collapse: collapse;
      margin: 24px 0;
      background: #ffffff;
      border-radius: 12px;
      overflow: hidden;
      box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    
    .specs-table th,
    .specs-table td {
      padding: 18px 24px;
      text-align: left;
      border-bottom: 1px solid var(--border);
    }
    
    .specs-table th {
      background: linear-gradient(135deg, var(--primary) 0%, var(--primary-light) 100%);
      color: white;
      font-weight: 600;
      font-size: 0.9em;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    
    .specs-table tr:last-child td {
      border-bottom: none;
    }
    
    .specs-table tr:hover {
      background: var(--bg-light);
    }
    
    .specs-table td:first-child {
      font-weight: 600;
      color: var(--text-dark);
    }
    
    /*bullet points*/
    ul {
    margin: 2px 0 2px 0;
    padding-left: 24px;
    color: #4a5568;
    line-height: 1.8;
    font-size: 1.05em;
    }



    /* Team Grid */
    .team-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
      gap: 24px;
      margin: 30px 0;
    }
    
    .team-member {
      background: linear-gradient(135deg, var(--bg-light) 0%, #edf2f7 100%);
      padding: 28px 24px;
      border-radius: 12px;
      text-align: center;
      border: 1px solid var(--border);
      transition: all 0.3s ease;
    }
    
    .team-member:hover {
      transform: translateY(-6px);
      box-shadow: 0 12px 28px rgba(0,0,0,0.12);
      border-color: var(--accent);
    }
    
    .team-member strong {
      color: var(--primary);
      font-size: 1.15em;
      display: block;
      margin-bottom: 8px;
    }
    
    .team-member span {
      color: var(--text-gray);
      font-size: 0.9em;
      display: block;
    }

    /* Team member link styling */
    .team-member a {
      color: var(--primary); 
      text-decoration: none; 
      font-weight: 600;
    }

    .team-member a:visited {
      color: var(--primary);
    }

    .team-member a:hover {
      text-decoration: underline;
    }
    
    /* Footer */
    footer {
      background: linear-gradient(135deg, var(--primary) 0%, var(--accent) 100%);
      color: rgba(255,255,255,0.95);
      padding: 40px 20px;
      text-align: center;
      margin-top: 80px;
    }
    
    footer p {
      color: rgba(255,255,255,0.95);
      margin-bottom: 8px;
    }
    
    /* Responsive */
    @media (max-width: 768px) {
      .header-content {padding: 70px 30px 50px;}
      header h1 {font-size: 2.2em;}
      .header-subtitle {font-size: 1.1em;}
      .container {padding: 40px 30px; margin: 30px 20px;}
      h2 {font-size: 1.8em;}
      .nav-container {padding: 12px 20px;}
      .nav-buttons a {font-size: 0.85em; padding: 8px 16px;}
      .image-placeholder {height: 250px; font-size: 0.95em;}
    }
  </style>
</head>
<body>
<header>
  <div class="header-content">
    <h1>NanoLogic</h1>
    <div class="header-meta">
      <span class="header-meta-item">EE6350 Spring 2025</span>
      <span class="header-meta-item">Columbia University</span>
      <span class="header-meta-item">TSMC 65nm</span>
    </div>
    
    <div class="author-info">
      <div class="authors-list">
        <a href="https://www.linkedin.com/in/qianxufu/" class="author-name">Qianxu Fu (Tiffany Fu)</a>
        <a href="https://linkedin.com/in/username" target="_blank" class="author-name">[Author Name 2]</a>
        <a href="mailto:email@columbia.edu" class="author-name">[Author Name 3]</a>
      </div>
    </div>
  </div>
</header>

<nav class="nav-buttons">
  <div class="nav-container">
    <a href="#introduction">Introduction</a>
    <a href="#architecture">Architecture</a>
    <a href="#design-flow">Design Flow</a>
    <a href="#software">Software & Testing</a>
    <a href="#pcb">PCB Design</a>
    <a href="#demo">Demonstration</a>
    <a href="#specs">Specifications</a>
    <a href="#conclusions">Conclusions</a>
    <a href="#references">References</a>
    <a href="#acknowledgments">Acknowledgments</a>
  </div>
</nav>

<div class="container">
  <a class="back" href="../index.html">Back to all projects</a>
  
  <section id="introduction">
    <h2>Introduction</h2>
    <p class="instruction-text">Our project is a fully integrated RISC-V based SoC chip fabricated in TSMC 65 nm CMOS technology. The system is built around the OpenHW Group’s CORE-V CV32E40P RISC-V CPU core, connected through an AHB-based system bus with AHB-to-APB bridges to access a rich set of on-chip peripherals.
</p>
    <p>The SoC integrates Instruction Memory, Data Memory, SPI, UART, 8 GPIOs, and two programmable timers, along with an on-chip clock generator, a debug finite-state machine, and a scan chain for DFT. The complete flow, from project proposal, architecture design, RTL implementation, verification, synthesis, physical design, signoff, and STA, all the way to PCB design, bring-up, and system-level validation, was carried out by our team. The final chip successfully runs on hardware and passes our functional demo.
</p>
      <img src="../images/nanologic/overview.HEIC" alt="System block diagram">
      <p class="caption">Figure 1. Whole System on PCB</p>

  </section>
  
  <section id="architecture">
    <h2>System Architecture</h2>
    <p class="instruction-text">The SoC adopts a modular architecture organized around a RISC-V CPU core, an AMBA-based interconnect, and a set of memory-mapped peripherals, memory and infrastructure blocks. All components are integrated within a compact 2 mm² die implemented in TSMC 65 nm CMOS technology.
</p>


<img src="../images/nanologic/block_diagram.png" alt="System block diagram">
      <p class="caption">Figure 2. SoC Chip Block Diagram</p>

    
    <h3>Main Components</h3>
     <p class="instruction-text">[Describe each major component: processing cores, memory subsystems, I/O interfaces, control logic, etc.]</p>
 
     <h4>CPU</h4>
     <p>At the heart of the chip is our RISC-V CPU core, which executes all application and control software and serves as the sole bus master in the system. The core interfaces with the on-chip interconnect through a lightweight AHB master port, giving it unified access to data storage and all memory-mapped peripherals.
    Importantly, instruction memory (IMEM) is not accessed through the AHB bus. Instead, it is directly connected to the CPU core, enabling a dedicated and deterministic instruction fetch path that simplifies timing and reduces bus traffic.
  </p>
  <p>
The CPU used in this project is version 1.8.3 of the OpenHW Group's RISC-V Core CV32E40P [1]. This core has been previously taped out as part of OpenHW's CORE-V MCU Development Kit; version 1.8.3 has undergone both formal verification and synthesis-based verification across multiple configurations, making it a mature and reliable open-source processor choice.
  <p>
The CV32E40P is a 32-bit, in-order, 4-stage pipeline processor implementing RV32I, RV32M, RV32C, and either RV32F or RV32Zfinx instruction sets. It also supports the PULP custom extensions for enhanced performance.
  </p>
  <p>
For our project, we selected the RV32Zfinx variant, which reuses the general-purpose register file for floating-point operations instead of requiring a dedicated floating-point register file, making it significantly more area-efficient than RV32F.
During the early front-end architecture planning, we initially enabled floating-point support and intended to include the FPU. However, during the physical design phase, we identified significant challenges with timing closure and area overhead introduced by the FPU. Since floating-point computation was not essential to our intended functionality or demo, we ultimately disabled floating-point hardware support to ensure a more robust, compact, and timing-clean implementation.
  </p>

   <p>
      <em>CV32E40P Core</em><br>
The CPU shown in the diagram is based on the CV32E40P core, a 4-stage, in-order RISC-V processor optimized for embedded and low-power applications. Its microarchitecture consists of the classic IF, ID, EX, and WB pipeline stages, with tightly integrated control logic to manage instruction flow, hazard resolution, and power-saving modes. The front end includes a prefetch buffer, instruction aligner, and compressed instruction decoder to improve instruction delivery efficiency. The register file and decoder feed multiple execution units, including an ALU, multiplier/divider, CSR unit, and an optional floating-point unit, enabling a wide range of integer and arithmetic operations. A dedicated Load-Store Unit (LSU) handles memory accesses and interacts with the external data interface. The core also integrates specialized units such as hardware loop registers, debug interface, interrupt controller, and a sleep unit for fine-grained power management. Overall, the design delivers a compact, configurable, and energy-efficient RISC-V processing solution suitable for microcontroller-class systems.
   
  <img src="../images/nanologic/CV32E40P_Block_Diagram.png" alt="System block diagram">
        <p class="caption">Figure 3. CV32E40P CPU Core [1]</p>
</p>

   <p>
       <em>Clock Gating</em><br>
In our CPU design, we adopt a hierarchical clock-gating strategy at the top level to reduce dynamic power consumption. Instead of implementing custom gating logic, we directly use the Integrated Clock Gating (ICG) cells, which provide reliable and PVT-safe clock gating.
   </p>
   <p>
    At the top level, the clock network is divided into several functional domains, such as the core pipeline, memory subsystem, and peripheral modules. Each domain receives a gated clock through an ICG cell, and the enable signal is generated based on the activity of the corresponding module. When a module is idle, its clock is disabled, effectively reducing unnecessary switching activity.
   </p>
   <p>
    ICG cell integrates a latch and gating logic to ensure glitch-free clock gating, and also includes a test-enable input for scan and DFT support. Using this standard, fully characterized cell guarantees safe operation and seamless integration with synthesis, CTS, and STA.
   </p>
   <img src="../images/nanologic/icg.png" alt="System block diagram" style="display:block; margin:0 auto; width:60%; height:auto;"><br>
          <p class="caption">Figure 4. ICG Cell</p>
   <br><br>
      <p>
      <em>FPU</em><br>
We originally planned to integrate an FPU into the SoC and successfully completed the compiler and linker configuration required to support floating-point operations. The FPU passed our initial functional simulations and worked correctly at the RTL level. However, after synthesis, physical design and timing analysis, the module introduced a tight timing that could not be resolved within our performance targets. To maintain overall system stability and achieve a much higher operating frequency, we ultimately decided to remove the FPU. Without the FPU's long combinational paths, the SoC's maximum clock period improved from 15 ns to 5 ns, resulting in substantially better performance and a more reliable design.
  <img src="../images/nanologic/FPU.png" alt="FPU">
            <p class="caption">Figure 5. Floating Point Operations</p>
   </p>
   <h4>Memory</h4>
<p>
The SoC adopts a Harvard memory architecture, featuring fully separated instruction and data memories to maximize throughput and simplify timing. The memory subsystem consists of two on-chip SRAM blocks:<br>
  <br> 
  <strong>Instruction Memory (IMEM):</strong> Directly connected to CPU fetch interface.<br>
  <strong>Data Memory (DMEM):</strong> AHB slave accessed by CPU load/store instructions.<br>

  <br>
  The instruction memory provides a dedicated, point-to-point connection to the CPU's instruction fetch interface. By avoiding the system bus entirely, IMEM enables deterministic instruction delivery, lower latency, and reduced bus contention.
Originally, the design targeted 32 KB of instruction storage, but due to strict die-area constraints during physical design, the IMEM size was adjusted to 16 KB, which still meets the needs of our target workloads and demo applications.
  <br>
  <br>
  The data memory is implemented as an AHB slave and connected to the CPU via the shared bus. All load/store instructions are routed through this bus interface, maintaining a clean separation between instruction fetch and data access. Similar to IMEM, DMEM was initially planned as 32 KB, but was downsized to 16 KB to fit within the allowable silicon footprint.
  <br>
  <br>

  <strong>SRAM Implementation and Memory Wrapper</strong><br>
  Both IMEM and DMEM are implemented as SRAM hard macros generated using the TSMC 65 nm memory compiler[make clear of this]. Since these macros are technology-specific and lack native support for system-level protocols or scan operations, we designed custom memory wrapper modules to ensure clean integration into the SoC.<br>
  <br>
  The memory wrappers provide several key functions:<br>
<ul>
  <li>Adapt the SRAM macro interfaces to the CPU and AHB protocol requirements. Manage functional control signals including read/write enables, chip-select, and byte enables.</li>
  <li>Implement a dedicated mode-switching mechanism that supports both normal run mode and DFT scan mode.</li>
  <li>Adding delay cells to avoid hold violation.Provide a clean, synthesizable interface for RTL simulation while isolating technology-specific macro details.</li>
</ul>
</p>
<p>
  <strong>Run Mode</strong><br>
In run mode, the wrapper exposes the memory as part of the functional SoC:
<ul>
<li>IMEM connects directly to the CPU's instruction-fetch interface.</li>
<li>DMEM operates as an AHB slave, servicing all CPU load/store requests via the system bus.</li>
<li>All functional address, control, and data signals drive the SRAM in this mode.</li>
</ul>
</p>

<p>
  <strong>Scan Mode</strong><br>
To enable complete chip-level scan coverage, the wrappers include logic that reconfigures the memory into scan mode during DFT operation:
<ul>
<li>The memory wrapper becomes part of the SoC's continuous scan chain, enabling scan vector to scan-in / scan-out. </li>
</ul>
</p>

<div class="image-placeholder">Insert scan chain relative pictures</div>


    <h4>On-Chip Interconnect and Bus Architecture</h4>
<p>
A central AMBA AHB system bus forms the primary communication backbone of the SoC. The bus is organized in a 1-master / 6-slave (M16S) topology, with the RISC-V CPU core acting as the only AHB master. It helps keep the interconnect simple, low-latency, and area-efficient.
<br>
<br>
Among the AHB slaves, the data memory (DMEM) is connected directly to the AHB bus as an AHB slave. All load/store instructions issued by the CPU are translated into AHB transactions through the LSU module, providing a straightforward path for data accesses.
<br>
<br>
All other low-bandwidth, register-mapped peripherals are accessed indirectly through an AHB-to-APB bridge, which itself appears as an AHB slave on the system bus. Behind this bridge, a set of APB peripherals is instantiated, including:
<ul>
<li>GPIO</li>
<li>SPI</li>
<li>UART</li>
<li>I²C</li>
<li>Two general-purpose Timers</li>
</ul>
</p>
<p>
The AHB-to-APB bridge decouples the higher-speed AHB domain from the simpler APB domain by:
<ul>
<li>Translating AHB read/write transactions into APB transfers</li>
<li>Generating APB select, enable, and write control signals for each peripheral</li>
<li>Isolating the timing and fan-out of the peripheral bus from the main system bus</li>
</ul>
</p>
<img src="../images/nanologic/apb.png" alt="System block diagram" style="display:block; margin:0 auto; width:60%; height:auto;"><br><br>
            <p class="caption">Figure 6. APB FSM Diagram [2]</p>
    <h4>Peripherals</h4>
<p>
<strong>SPI</strong><br>
The first of the peripherals will be SPI (Serial Peripheral Interface). SPI is a high-speed, full-duplex, synchronous serial communication protocol commonly used for data transmission between microcontrollers and peripherals. In our design, we use the open-source SPI from Pulp-Platform Group to connect with the display.
</p>

<p>
<strong>UART</strong><br>
The second of the peripherals will be UART (Universal Asynchronous Receiver/Transmitter). UART is an asynchronous serial communication protocol used for data transmission between devices. UART enables communication without a clock signal, where the transmitter and receiver synchronize data transmission based on a predefined baud rate. It uses separate transmit (TX) and receive (RX) signals, allowing simultaneous data transmission and reception. The data follows the Start bit - Data bits - Parity bit - Stop bit format.
</p>

<p>
<strong>GPIO</strong><br>
The third of the peripherals will be GPIO (General-Purpose Input/Output). The GPIO module is designed to facilitate basic communication with external devices through 8 GPIO pins. On the output path, each pin is controlled by a simple register, which is updated whenever a write request is received from the bus. On the input path, a synchronizer composed of two back-to-back registers is implemented to prevent metastability. This ensures reliable input capture even under asynchronous conditions. When the processor issues a read request, the synchronizer's output value for the relevant pin is sent to the bus. This streamlined GPIO module balances simplicity and functionality, making it suitable for the proposed chip’s requirements.
</p>

<p>
  <strong>I2C</strong><br>
The fourth peripheral will be I2C (Inter-Integrated Circuit). Our design integrates an open-source I2C master controller to enable communication between devices using just two lines: SDA (data) and SCL (clock). The master handles operations like start, stop, read, and write, while also monitoring the bus status and managing multi-master arbitration. I2C has efficient pin usage, ability to support multiple peripherals through unique addresses, and compatibility with a wide range of low-speed devices like sensors and EEPROMs.
</p>

<p>
  <strong>Timer</strong><br>
The last peripheral will be a set of timers. The timer is a versatile module designed to manage timing operations, generate events, and control pulse-width modulation (PWM). It supports both count-up and count-down modes and can operate with sawtooth or triangle wave counting patterns. Timers synchronize events based on internal or external clock signals, making them suitable for various system control tasks such as delays, periodic interrupts, and signal generation. The timer configuration includes start and end counters, prescaler settings, and multiple compare channels. It generates interrupt or event signals upon matching the configured thresholds, enabling seamless integration into time-sensitive applications.
</p>

    <h4>DFT Components</h4>
<p>
  <strong>Scan Chain</strong><br>
  The chip integrates a unified scan chain consisting of 248 scan cells, enabling full controllability and observability of key internal signals during DFT (Design-for-Test) and silicon bring-up. The scan chain forms a single linear shift register that spans across modules including the instruction memory interface, data memory interface, clock generator, and the debug FSM.
  <br>
  <br>
  The 248 scan cells connect a wide range of internal signals, including:
  <ul>
<li>IMEM signals: IMEM control, address, write enable, read and write data.</li>
<li>DMEM signals: DMEM control, address, write enable, read and write data.</li>
<li>Clock generator control signals.</li>
<li>Debug FSM control and status signals.</li>
</ul>
</p>
<p>
These signals are flattened into a single contiguous scan path:<br>
   <img src="../images/nanologic/scanchain.png" alt="System block diagram" style="display:block; margin:0 auto; width:60%; height:auto;">
   <p class="caption">Figure 5. Scan Chain</p>
</p>
<p>
This structure allows external test equipment or debugging software to shift in arbitrary patterns and read out internal states at any point.<br>
<br>
<em>Scan Mode Operation</em><br>
In scan mode, the SoC suspends normal functional dataflow and all memory wrapper modules switch into test configuration:
<ul>
  <li>Functional read/write ports of IMEM and DMEM are disabled.</li>
  <li>Scan-in (SI) and scan-out (SO) signals propagate through the entire chain.</li>
  <li>All control signals connected to the scan chain are driven purely by the shifted scan data.</li>
  <li>The scan chain scan in instructions into IMEM and data into DMEM, for initialization.</li>
  <li>The scan chain can also read out the content of DMEM after program execution, enabling full post-silicon inspection of computation results.</li>
  </ul>
</p>
<p>
<em>Run Mode Operation</em><br>
When scan mode is deactivated, the memory wrappers and control signals reconnect to their functional sources:
<ul>
  <li>The CPU fetches instructions directly from IMEM.</li>
  <li>The CPU accesses DMEM via the AHB bus.</li>
  <li>Clock generator works under setting.</li>
  <li>No scan traffic influences the logic.</li>
  </ul>
</p>
<p>The transition between scan mode and run mode is cleanly controlled to ensure no metastability or unintended corruption of memory or control registers.</p>

<br>
<strong>Clock Generator</strong><br>
The clock generator is based on a ring oscillator whose output frequency can be configured at runtime through two control registers:
<ul>
  <li>fc (frequency control) - selects the effective length of the ring oscillator, thereby adjusting the base oscillation frequency. Different fc settings correspond to different numbers of delay stages in the ring.</li>
  <li>div (divider) - applies a programmable integer divide ratio to the ring oscillator output, generating a lower-frequency system clock when needed.</li>
</ul>
<p>By combining the fc and div settings, the SoC can trade off performance, power consumption, and timing margin. These control bits are loaded via the scan chain, allowing the clock configuration to be changed even when no firmware is running yet.
The final clock output of the generator is routed to the CPU core, AHB bus, memories, and peripherals, forming the primary system clock domain.</p>

<br>
<strong>Debug FSM</strong>
<p>A debug FSM orchestrates how the generated clock is delivered to the rest of the chip. The FSM supports three operating modes:<br>
<em>Scan Mode: </em>The system clock isn't launched, and no clock edges are propagated to the CPU or peripherals. In this mode the scan chain can working, as the IMEM and DEME's clock will be depend on outside scan-in clock signal.<br>
<em>Running Mode: </em>The clock generator output is continuously forwarded through the scan-controlled clock gating logic to the system clock tree. The SoC operates normally in this mode: the CPU executes instructions from IMEM, accesses DMEM over AHB, and interacts with APB peripherals.<br>
<em>Debug Mode: </em>The FSM enables the clock for a programmable number of cycles and then automatically returns to a paused state. It allows engineers to advance the system by a controlled number of clock edges, then inspect internal state or memory contents via the scan chain.<br>
<br>
Mode selection, as well as auxiliary control signals (such as step length in debug mode), are themselves loaded through the scan chain. This allows complete control of clock behavior from external test equipment without relying on software.
</p>
   <img src="../images/nanologic/fsm.png" alt="System block diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
   <p class="caption">Figure 6. Debug FSM</p>

  </section>
  
  <section id="design-flow">
    <h2>Design Flow</h2>
   <p>This tape-out project follows a complete ASIC development flow that spans front-end design, back-end physical implementation, and post-silicon validation. The process begins with the system specification and microarchitecture design, where the functional requirements and architectural structure of the chip are defined. Based on this specification, the RTL is implemented in Verilog/SystemVerilog.
    </p>
    <p>
    During the functional verification phase, both hardware testbenches and software programs are used. We developed a full RISC-V software toolchain and compiler to generate C-based testcases, allowing us to verify the CPU core using real workloads and instruction sequences. This hardware–software co-verification ensures correctness at both the microarchitectural and ISA levels before synthesis.
       </p><p>
    After verification, the RTL is synthesized into a gate-level netlist, followed by post-synthesis timing and functional checks. The design then enters the physical design flow, including floorplanning, power planning, placement, routing, and clock tree synthesis. I/O pad integration and layout optimization are performed prior to signoff verification, which includes STA, DRC, LVS, and ERC. Once the design passes all signoff checks, the final GDSII is generated and sent for tape-out.
    </p>
   <p>
    Following fabrication, the bare dies are packaged and undergo bring-up on both a breadboard environment and a dedicated PCB. The entire PCB, including power regulation, signal breakouts, connectors, and measurement points, was fully designed by our team, with all components hand-selected to support chip evaluation. Silicon validation verifies real-chip functionality, performance, and power consumption. After successful validation, the chip is used for demonstrations and system-level experiments.
  </p>

          <img src="../images/nanologic/designflow.png" alt="System block diagram">
          <p class="caption">Figure 7. Chip Design Flow</p>

    <h3>RTL Design</h3>
    <p>The RTL design of the SoC was developed and compiled using the ModelSim simulation environment. The codebase follows a clear hierarchical structure that separates chip-level integration, functional logic, and DFT infrastructure. At the highest level, the design begins with soc-pins, which connect the internal SoC signals to the padframe. Directly beneath it is soc-top, the actual top-level RTL of the chip. This module contains both the functional SoC and the DFT subsystem, which are designed as two independent power domains: the DFT logic operates under VDD_Test, while all functional logic is powered by VDD_Core. This separation ensures safe testing in scan mode without interfering with normal system behavior.
    </p>
    <p>
    The functional portion of the chip is encapsulated in soc_mem, which contains the CPU core, memory subsystem, bus fabric, and peripheral subsystem. The CV32E40P RISC-V core connects directly to IMEM for instruction fetch, while DMEM access is performed through the AHB bus. Both memories are instantiated through custom wrappers that interface the synthesized RTL with the SRAM macros and support both run mode and scan mode. The same module instantiates the AHB interconnect, the AHB-to-APB bridge, and all APB peripherals, including UART, SPI, GPIO, I²C, and timers. This organization places all processor-visible functionality inside a single coherent RTL subsystem.
    </p>

    <p>
    On the DFT side, soc-top integrates the full-chip scan chain, scan-mode clock control, and debug FSM, along with a separate test-mode clock generator netlist used for DFT simulations. The scan chain spans 248 cells and provides controllability and observability across CPU state, memory wrapper mode bits, the clock generator configuration registers, and peripheral-related scan points. This allows instructions and data to be shifted directly into IMEM and DMEM during bring-up, while also enabling cycle-stepping through the debug FSM.
    </p>
    <p>
    Overall, the RTL is organized to cleanly separate functionality and test logic while maintaining a modular structure that mirrors the physical hierarchy of the final chip. This structure supported efficient simulation, synthesis, and later physical design, and provided a clear boundary between the functional SoC and its DFT infrastructure.  
    </p>
      <img src="../images/nanologic/rtl.png" alt="System block diagram">
      <p class="caption">Figure 7. RTL Modules Architecture</p>


    <h3>Design Verification</h3>
    <p>The verification of the SoC followed a directed-test methodology using a custom SystemVerilog testbench together with C-based test programs compiled for the RISC-V architecture. Instead of building a full UVM environment, we adopted a focused, system-driven verification approach that closely matches the behavior of the real chip during board-level bring-up. This allowed us to validate both the functional design and the DFT infrastructure under realistic operating conditions.</p>
    <p>All test cases were written as C programs, compiled using the RISC-V GCC toolchain, and executed directly on the embedded CV32E40P CPU core. These tests exercise the RTL in the same way real firmware will, enabling software-driven verification of processor execution, memory behavior, bus transactions, and peripheral functionality. A variety of targeted test programs were developed to isolate and validate individual modules—including DMEM read/write patterns, SPI transfers, UART transmission, GPIO toggling, I²C transactions, and timer interrupts. In addition to unit-level tests, we also created integrated programs that combine multiple peripherals and CPU-bus interactions to ensure correct end-to-end system behavior. More details of the test program structure and software toolchain will be described in the Software section.</p>
    <p>The SystemVerilog testbench models the full bring-up sequence of the physical chip. Before each run, the testbench assembles the 248-bit scan-in vector by organizing the scan chain fields according to their functional purposes, including IMEM contents, DMEM initialization, clock generator configuration, and FSM mode bits. Verification begins with a global reset, followed by placing the internal FSM into scan mode so that the testbench can shift instructions and configuration data into the scan chain. Once the scan load is complete, the FSM transitions into run mode, enabling the CPU to fetch instructions from IMEM and execute the compiled C program. Waveforms are monitored during execution to observe CPU behavior, AHB and APB transactions, peripheral activity, and memory accesses, ensuring architectural and protocol correctness.</p>
    <p>After program execution finishes, the FSM is switched back into scan mode to shift out DMEM data. By comparing the scanned-out results against the expected outputs generated by the C testcase, we verify the correctness of program execution, the integrity of the scan chain, and the functionality of the memory wrappers. This verification flow—reset → scan-in → run → scan-out—exactly mirrors the operational steps used during post-silicon bring-up, ensuring a high degree of consistency between pre-silicon simulation and hardware validation.
</p>
      <img src="../images/nanologic/dv1.png" alt="hierarchy">
      <p class="caption">Figure 7. GPIO Write Test Case</p>

      <img src="../images/nanologic/dv2.png" alt="DC - Total Cell Area">
      <p class="caption">Figure 7. GPIO READ and Memory Test Case</p>

      <img src="../images/nanologic/dv3.png" alt="DC - Total Cell Area" >
      <p class="caption">Figure 7. Chip Design Flow</p>

    <h3>Synthesis</h3>
    <p>The synthesis stage translated the RTL design into a gate-level netlist using the TSMC 65 nm standard-cell library. Before synthesis, the RTL underwent linting and cleanup to ensure complete synthesizability and consistent signal definitions across modules. We constructed a comprehensive set of timing and design constraints, including the system clock specification, input and output delays, false-path and multicycle-path declarations, and mode-specific constraints for both functional and scan operation. These constraints ensured that the synthesis tool accurately captured the intended timing behavior of the SoC across all subsystems.
</p>
    <p>During synthesis, the memory wrappers were configured to replace their behavioral models with the actual SRAM hard macros generated by the memory compiler. The wrappers provided the necessary functional and scan-mode interfaces so that the macros could be seamlessly integrated into both the RTL and gate-level flows.</p>
    <p>In our synthesis flow, we follow a hierarchical methodology aligned with the RTL file organization. All IP modules—such as the CPU core, SPI, UART, I2C, GPIO, timer, scan chain, and various FSMs—are synthesized individually to ensure modularity and ease of debugging. When synthesizing the SoC-level design, we include the previously generated netlists for these IP blocks and then proceed with synthesizing the SoC bus, SoC memory subsystem, and SoC top, together with the SRAM integration files.</p>
    <p>For each test case, we perform post-synthesis gate-level simulation to validate functional correctness. Due to several modules exhibiting hold-time violations, not all test cases pass at this stage. These hold issues are expected and will be resolved during the physical design (PD) stage through proper buffering and timing refinement. Importantly, we ensure that there are no setup-time violations after synthesis, providing a solid timing foundation for the subsequent place-and-route process.</p>
    <p>Following synthesis, we generated reports for area utilization, hierarchical timing, constraint coverage, and scan connectivity. The final synthesized netlist, along with the macro placement constraints and clock definitions, was handed off to the physical design stage for floorplanning and place-and-route. This marked the transition from RTL-level development to backend implementation.</p>
      <img src="../images/nanologic/dc1.png" alt="System block diagram" style="display:block; margin:0 auto; width:60%; height:auto;"><br>
      <p class="caption">Figure 7. Chip Design Flow</p>
      <br><br>
      <img src="../images/nanologic/dc2.png" alt="System block diagram" style="display:block; margin:0 auto; width:60%; height:auto;"><br>
      <p class="caption">Figure 7. Chip Design Flow</p>

    <h3>Physical Design</h3>
    <p>The physical design of the chip is implemented using Cadence Innovus for place-and-route and Cadence Virtuoso for final layout verification. We adopt a relatively simple but structured floorplan. The core complex, including the CPU core, system bus, and peripheral modules, is laid out as a single main block located at the center of the die. The instruction memory (IMEM) and data memory (DMEM) are implemented as two dedicated rectangular SRAM macros placed on the left and right sides of the core, respectively, to minimize critical-path interconnect length between the processor and the memories. The FSM, clock generation logic, and scan chain controller are grouped together and placed along one side of the chip. Since these blocks share the same power domain, this placement simplifies power distribution and also provides a clean topology for scan chain routing toward the rest of the design. IO pads are inserted along all four edges of the chip to interface the internal logic with the external environment and to close the power ring.
</p>
    <p>Our physical design flow in Innovus follows a standard industrial methodology. We begin by creating the floorplan, defining the core area and placing the major macros according to the architecture partition described above. Next, we generate the global and local power rails, ensuring robust power delivery to all modules in the single power domain. After that, we define and constrain all input and output ports, including timing constraints and IO placement guidelines. The standard-cell placement step is then performed, followed by pre-CTS (clock tree synthesis) optimization to reduce congestion, fix early timing issues, and improve design quality before building the clock tree.</p>
    <p>We then perform clock tree synthesis to distribute the clock to all sequential elements while controlling skew and insertion delay. A round of post-CTS optimization is run to clean up timing violations that emerge after the clock network is inserted. Once the clocks and standard cells are in good shape, we proceed to signal routing, including global and detailed routing, to connect all nets while honoring design rules. After routing, we run extraction to generate accurate parasitic (RC) information and conduct further timing and design optimizations. At this stage, decoupling capacitors and filler cells are inserted as needed to maintain power integrity, close metal density requirements, and ensure manufacturability. Finally, the design goes through a series of verification steps within Innovus (such as basic DRC and timing checks), and the tape-out-ready layout and associated views are exported.</p>
    <p>As mentioned earlier in the synthesis section, some modules exhibited hold-time violations at the netlist level. These issues are systematically resolved during the place-and-route stage. Using post-route parasitic information, we perform hold-fixing in Innovus by inserting delay cells and adjusting routing where necessary. Our goal is to eliminate all hold-time violations while preserving setup-time margins, so that the final implementation is both functionally correct and timing-clean under the target operating conditions.</p>
    <p>After the place-and-route flow is completed, the final layout is imported into Cadence Virtuoso for signoff-level physical verification. We perform full-layout DRC (Design Rule Check) and LVS (Layout Versus Schematic) to ensure that the layout is free of rule violations and is electrically consistent with the synthesized netlist. In addition, we back-annotate the extracted delay information into our simulation environment and re-run the full set of test cases at the gate-level with timing. All test cases are verified to pass with correct waveforms and converged timing behavior, providing strong confidence in both functionality and implementation quality.</p>
    <p>For timing signoff, we use Synopsys PrimeTime to perform static timing analysis across the relevant process, voltage, and temperature corners. Based on the extracted parasitics from the routed layout, we verify that no setup or hold violations remain on any timing path and that there are no additional issues such as excessive clock skew or unconstrained paths. Through this combination of Innovus PnR, Virtuoso physical verification, gate-level simulations with back-annotated delays, and PrimeTime static timing analysis, we ensure that the design is ready for fabrication with clean physical, functional, and timing signoff.</p>
    <img src="../images/nanologic/pd1.png" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Core & Bus & Pheripherals Layout</p>
    <img src="../images/nanologic/pd_sc.png" alt="layout diagram">
    <p class="caption">Figure ?. Scan Chain Layout</p>
    <p>In our physical design, the standard vertical power rails for each small module are implemented at metal layer M6, while the horizontal local power routing within the modules uses M1. Because the soc_mem block—which contains the CPU core, peripherals, and the two memory macros—also relies on vertically oriented power rails, its power grid must be precisely aligned with the internal module rails. Even a small offset would cause DRC violations due to misaligned straps or insufficient metal overlap. At the chip’s top level (soc_pin), the global power distribution network transitions to a higher metal layer, where wide horizontal power rails are used to provide low-resistance current delivery across the full SoC. This hierarchical alignment of vertical and horizontal power structures ensures correct connectivity, prevents DRC errors, and supports stable power distribution throughout the design.</p>
    <img src="../images/nanologic/layout.png" alt="layout diagram">
    <img src="../images/nanologic/layout2.png" alt="layout diagram">
    <p class="caption">Figure ?. Layout Pictures</p>
    
    <h3>Packaging Overview</h3>
    <p>The fabricated die has dimensions of 1000 µm × 2000 µm, and contains a total of 66 bond pads distributed symmetrically around the four sides of the chip. The pad arrangement consists of 25 pads on the north side, 25 pads on the south side, 8 pads on the west side, and 8 pads on the east side, providing full access to power rails, I/O interfaces, clocks, scan signals, and debug ports.
</p>
    <p>Each bond pad follows the standard TSMC 65 nm pad-frame specification. The nominal pad opening is 60 µm × 190 µm, or 30 µm × 190 µm when excluding the spacing region. This ensures compatibility with conventional gold wire bonding processes used in QFP and LQFP packaging flows.</p>
    <p>A total of 20 dies will be packaged, with the primary package type selected as LQFP64L, which provides sufficient lead-out pins for all I/O and supply connections while maintaining a compact and low-cost footprint suitable for PCB mounting and system-level testing. The pad-to-pin mapping has been verified to comply with the 64-pin lead frame configuration.
      <br><br>
    <em>Power and Ground Bonding</em><br>
    All VSS pads are highlighted in magenta in the bond diagram and are down-bonded directly to the exposed paddle, ensuring a low-impedance return path for the core and I/O grounds. This improves noise performance, reduces supply bounce during high-activity conditions, and provides robust ESD protection. The VDD rails are bonded individually to dedicated package pins to allow independent supply measurement and external regulation.
    </p>
    <p>
          <em>Bonding Diagram and Pinout</em><br>
        The bonding diagram shows the complete mapping between die pads and LQFP64L pins. Power, ground, GPIO, SPI, UART, scan chains, and test signals are organized to minimize crossing wires and to maintain short bond lengths. This arrangement improves manufacturability, reduces parasitic inductance, and enhances reliability.
    </p>
    <img src="../images/nanologic/bond_table.png" alt="layout diagram">
        <p class="caption">Figure ?. Bond Table</p>
        <img src="../images/nanologic/bond_diagram.png" alt="layout diagram" style="display:block; margin:0 auto; width:80%; height:auto;"><br>
            <p class="caption">Figure ?. Bond Diagram</p>
  </section>
  
  <section id="software">
    <h2>Software & Testing Flow</h2>
    <p class="instruction-text">[Replace with software and testing description: Explain the software stack, test programs, simulation methodology, and post-silicon validation approach.]</p>
        <img src="../images/nanologic/sw_flow.png" alt="layout diagram"><br>
    <p class="caption">Figure ?. Chip Software Flow </p><br>
    <h3>Software Development</h3>
    <p>The software development and testing workflow begins with writing programs in C, which serve as test cases for validating the functionality of our SoC. To support this, we built a complete RISC-V toolchain, including a customized linker script and memory configuration. Since our design follows a Harvard architecture with separate instruction memory (IMEM) and data memory (DMEM), the toolchain is configured to correctly place code sections into IMEM and data sections into DMEM. The RISC-V compiler translates C programs into machine code, while also generating assembly output to assist with debugging and instruction-level verification.
</p>
    <p>To support software development, we created a utility file named nano_logic_utils.c. This file contains essential definitions and helper functions used across all test programs, including clear memory-location mappings and frequently used operations tailored for our SoC. These utilities provide a standardized interface between software and hardware, allowing test programs to be written more easily and consistently.</p>
    <p>Once the C programs are compiled, the resulting machine code is loaded into the chip through the scan chain. During scan mode, the scan chain shifts the binary instructions directly into the IMEM and DMEM. After switching to run mode, the CPU begins fetching instructions from IMEM and executing them, allowing us to verify full-system behavior.</p>
    <p>A wide set of test programs has been developed to validate the CPU core, peripherals, and memory system. These include arithmetic tests, GPIO input/output tests, UART and SPI tests, LCD tests, DMA/DMEM access programs, timer tests, scan-chain diagnostics, and several demo applications such as menu navigation, games, and prime-number generation. All test cases pass both pre-synthesis and post-pnr simulations, and later the same test suite is executed again on the fabricated chip to confirm silicon correctness.</p>
    <p>Compiler progress 5</p>
    <p></p>



    <h3>Testing Methodology</h3>
    <p class="instruction-text">[Explain pre-silicon verification, post-silicon testing procedures, and measurement techniques.]</p>
    <p></p>
    <p></p>
    <p></p>
    <p></p>
    <p></p>
  
  </section>
  

  <section id="pcb">
    <h2>PCB Design</h2>
   <p>Before designing the PCB, we first validated the basic functionality of our system on a breadboard. This allowed us to quickly prototype the core components, verify signal correctness, and ensure that the chip interfaces behaved as expected. However, breadboard wiring is inherently limited in terms of signal integrity, power stability, reliability, and repeatability.</p>
   <p>The purpose of creating a dedicated PCB is to provide a stable, well-structured, and electrically robust platform for testing our chip. The PCB ensures controlled routing, proper grounding, low-noise power distribution, and mechanically secure connections—all of which are essential for accurate measurement and characterization. It also integrates voltage regulators, test points, connectors, and peripheral interfaces in a clean and reproducible layout, enabling more complex experiments that would not be practical on a breadboard.
</p>
   <p>Overall, the PCB transforms the project from an early prototype into a reliable test and evaluation system, supporting systematic bring-up, debugging, and performance testing of the chip.</p>
  <img src="../images/nanologic/board.HEIC" alt="layout diagram" style="display:block; margin:0 auto; width:60%; height:auto;"><br>
    <p class="caption">Figure ?. PCB </p>

    <h3>Board Architecture</h3>
    <p>The PCB is organized around the custom test chip placed at the center of the board, with all critical signals and supplies fanning out symmetrically. On the left side, an Arduino-UNO-compatible header provides a convenient digital interface for configuration, scan control, and simple firmware development. Around the chip, dedicated connectors expose scan, load, clock, and GPIO pins for lab instrumentation and external measurement.</p>
    <p>The lower portion of the board is reserved for the power-management section, where the LDO regulators and associated jumpers, test points, and decoupling networks are grouped together. Along the bottom edge, an array of Cherry MX push buttons is connected to the chip GPIOs through pull-down resistors, forming a simple and robust user input interface. Mechanical features such as mounting holes and the reserved LCD area are aligned with the board outline so that the complete system can be mounted in a chassis or demo fixture. This layout keeps high-current power paths short, separates digital I/O from sensitive supply routing, and makes probing and debugging straightforward during bring-up.</p>
    <img src="../images/nanologic/pcb1.png" alt="layout diagram"><br>
        <p class="caption">Figure ?. PCB </p>
    <img src="../images/nanologic/pcb2.png" alt="layout diagram" style="display:block; margin:0 auto; width:60%; height:auto;"><br>
        <p class="caption">Figure ?. PCB </p>

    <h3>Power Distribution</h3>
    <p>The board is powered from a 5 V input, which is locally regulated down to several on-board supply rails. Three TPS7A7100 LDO regulators generate the main voltages used by the chip: VDD_CORE, VDD_CLEAN, and VDD_TEST. Each regulator has its own input filter, adjustable feedback network, and output decoupling, allowing the core, clean, and test domains to be powered independently and tuned to the required voltage levels.</p>
    <p>For measurement and bring-up, every rail is routed through “pre” and “post” jumpers and dedicated test points. This allows an ammeter or shunt resistor to be inserted in series with the supply to monitor per-domain current consumption without modifying the PCB. Banks of bulk (10 µF) and high-frequency (100 nF) capacitors are placed close to the test chip pins on each rail to reduce supply noise and stabilize the regulators. The 3.3 V logic domain used by the GPIO switches and external connectors is kept separate from the core supplies, ensuring that digital I/O activity does not disturb the more sensitive core and clean power domains. Together, this power-distribution scheme provides flexible, low-noise, and well-observable supplies for detailed silicon characterization.
</p>
    <img src="../images/nanologic/pcb3.png" alt="layout diagram">
            <p class="caption">Figure ?. PCB </p>

  </section>
  
  <section id="demo">
    <h2>Demonstration</h2>
    <p class="instruction-text">[Replace with demonstration description: Show working examples, test results, and real-world performance of your chip.]</p>
    
    <img src="../images/nanologic/demo/default.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Starting Our Demo </p>

    <img src="../images/nanologic/demo/Prime.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Print Prime Numbers</p>

    <img src="../images/nanologic/demo/pai.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Print Pai </p>

    <img src="../images/nanologic/demo/game_menu.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Print Game Menu </p>

    <img src="../images/nanologic/demo/easy.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Easy Mode </p>
   
    <img src="../images/nanologic/demo/gameover.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Over </p>

    <img src="../images/nanologic/demo/normal.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Normal Mode  </p>

    <img src="../images/nanologic/demo/normal2.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Normal Mode Ongoing </p>
    
    <img src="../images/nanologic/demo/normal_wrong.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Normal Mode Wrong </p>

    <img src="../images/nanologic/demo/normal_over.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Normal Mode Over </p>

    <img src="../images/nanologic/demo/hard.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Hard Mode </p>

    <img src="../images/nanologic/demo/hard2.jpg" alt="layout diagram" style="display:block; margin:0 auto; width:50%; height:auto;"><br>
    <p class="caption">Figure ?. Game Hard Mode Ongoing </p>

    <h3>Video Demonstration</h3>
    <div class="video-container">
      <iframe src="https://youtu.be/iXhaCI2XmE" title="Project demonstration video" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </div>
  </section>
  
  <section id="specs">
    <h2>Chip Specifications</h2>
    <p class="instruction-text">[Replace with chip specifications: Provide detailed technical specifications and measured performance metrics.]</p>
    
    <table class="specs-table">
      <tr>
        <th>Parameter</th>
        <th>Specification</th>
      </tr>
      <tr>
        <td>Technology</td>
        <td>TSMC 65nm LP</td>
      </tr>
      <tr>
        <td>Die Size</td>
        <td>2.0mm × 1.0mm</td>
      </tr>
      <tr>
        <td>Maximum Frequency</td>
        <td>200 MHz</td>
      </tr>
      <tr>
        <td>Operating Frequency</td>
        <td>84.414 MHz</td>
      </tr>
      <tr>
        <td>Supply Voltage</td>
        <td>1.0 V core rails (VDD_CORE / VDD_CLEAN / VDD_TEST), 3.3 V I/O, 5 V board input</td>
      </tr>
      <tr>
        <td>Power Consumption</td>
        <td>[e.g., 85 mW typical]</td>
      </tr>
      <tr>
        <td>Performance Metric</td>
        <td>[e.g., throughput, latency]</td>
      </tr>
      <tr>
        <td>Package</td>
        <td>LQFP64L</td>
      </tr>
      <tr>
        <td>Gate Count</td>
        <td>~800,000 gates</td>
      </tr>
    </table>

     <br><br>
     <p>The table below defines the memory map of all major components connected to the SoC bus. Each peripheral is assigned a dedicated, non-overlapping address region to ensure simple decoding and deterministic access behavior. The on-chip data memory (DMEM) occupies the lower address space, enabling fast load/store operations from the CPU core. All memory-mapped peripherals—including GPIO, UART, SPI, I²C, and timer modules—are placed at aligned 4 KiB address boundaries on the bus. This organization allows the AHB/APB interconnect to efficiently route transactions based on the high-order address bits, while providing a clean, extensible structure for integrating additional peripherals in future revisions of the SoC. The CPU can interact with each module through standard load/store instructions, making software development straightforward and enabling uniform access across the entire system.</p>

 <table class="specs-table">
  <tr>
    <th>Device</th>
    <th>Start</th>
    <th>End</th>
    <th>Size</th>
  </tr>

  <tr>
    <td>DMEM</td>
    <td>0x00000000</td>
    <td>0x00007FFF</td>
    <td>16KiB</td>
  </tr>

  <tr>
    <td>GPIO</td>
    <td>0x10000000</td>
    <td>0x10000FFF</td>
    <td>4KiB</td>
  </tr>

  <tr>
    <td>UART</td>
    <td>0x20000000</td>
    <td>0x20000FFF</td>
    <td>4KiB</td>
  </tr>

  <tr>
    <td>SPI</td>
    <td>0x30000000</td>
    <td>0x30000FFF</td>
    <td>4KiB</td>
  </tr>

  <tr>
    <td>I2C</td>
    <td>0x40000000</td>
    <td>0x40000FFF</td>
    <td>4KiB</td>
  </tr>

  <tr>
    <td>Timers</td>
    <td>0x50000000</td>
    <td>0x50000FFF</td>
    <td>4KiB</td>
  </tr>

</table>

<br><br>
<p>In addition to the bus-mapped peripheral address space, the SoC includes a separate memory map for the instruction memory (IMEM). Unlike DMEM and the peripheral modules, IMEM is not connected to the AHB/APB system bus. A separate IMEM table is therefore provided to document its address boundaries and organization.</p>
 <table class="specs-table">
  <tr>
    <th>Device</th>
    <th>Start</th>
    <th>End</th>
    <th>Size</th>
  </tr>

  <tr>
    <td>IMEM</td>
    <td>0x00000000</td>
    <td>0x00007FFF</td>
    <td>16KiB</td>
  </tr>
  </table>

    <br><br>
    <p>The table below summarizes the output frequencies generated by the on-chip clock generator for different combinations of clkgen_div and clkgen_fc control signals. These configuration bits are loaded through the scan chain, allowing the clock generator to be fully programmable without requiring dedicated external pins. By shifting the desired divider (clkgen_div) and frequency-control (clkgen_fc) values into the scan chain and applying them during run mode, the SoC can dynamically select a wide range of operating frequencies. This programmability enables flexible performance scaling, thorough post-silicon characterization, and simplified validation of timing margins across various clock settings.</p>
    <table class="specs-table">
  <tr>
    <th>clkgen_div</th>
    <th>clkgen_fc</th>
    <th>Frequency (Hz)</th>
  </tr>
  <tr>
    <td>1111</td>
    <td>11111</td>
    <td>9.3424K</td>
  </tr>
  <tr>
    <td>1111</td>
    <td>01010</td>
    <td>20.682K</td>
  </tr>
  <tr>
    <td>1111</td>
    <td>00101</td>
    <td>29.361K</td>
  </tr>
  <tr><td>1110</td><td>01010</td><td>41.358K</td></tr>
  <tr><td>1110</td><td>00101</td><td>58.685K</td></tr>

  <tr><td>1101</td><td>01010</td><td>82.672K</td></tr>
  <tr><td>1101</td><td>00101</td><td>117.35K</td></tr>

  <tr><td>1100</td><td>01010</td><td>165.43K</td></tr>
  <tr><td>1100</td><td>00101</td><td>234.80K</td></tr>

  <tr><td>1011</td><td>01010</td><td>330.69K</td></tr>
  <tr><td>1011</td><td>00101</td><td>468.87K</td></tr>

  <tr><td>1010</td><td>01010</td><td>661.38K</td></tr>
  <tr><td>1010</td><td>00101</td><td>938.44K</td></tr>

  <tr><td>1001</td><td>01010</td><td>1.321M</td></tr>
  <tr><td>1001</td><td>00101</td><td>1.877M</td></tr>

  <tr><td>1000</td><td>01010</td><td>2.637M</td></tr>
  <tr><td>1000</td><td>00101</td><td>3.765M</td></tr>

  <tr><td>0111</td><td>01010</td><td>5.252M</td></tr>
  <tr><td>0111</td><td>00101</td><td>7.530M</td></tr>

  <tr><td>0110</td><td>01010</td><td>10.593M</td></tr>
  <tr><td>0110</td><td>00101</td><td>15.010M</td></tr>

  <tr><td>0101</td><td>01010</td><td>21.552M</td></tr>
  <tr><td>0101</td><td>00101</td><td>30.02M</td></tr>

  <tr><td>0100</td><td>01010</td><td>42.264M</td></tr>
  <tr><td>0100</td><td>00101</td><td>59.98M</td></tr>

  <tr><td>0011</td><td>01010</td><td>84.414M</td></tr>
  <tr><td>0011</td><td>00101</td><td>119.66M</td></tr>

  <tr><td>0010</td><td>01010</td><td>168.83M</td></tr>
  <tr><td>0010</td><td>00101</td><td>239.46M</td></tr>

  <tr><td>0001</td><td>01010</td><td>336.75M</td></tr>
  <tr><td>0001</td><td>00101</td><td>476.74M</td></tr>

  <tr><td>0000</td><td>01010</td><td>669.16M</td></tr>
  <tr><td>0000</td><td>00101</td><td>946.97M</td></tr>

  <tr><td>0000</td><td>00000</td><td>1.524G</td></tr>
</table>

  </section>
  
  <section id="conclusions">
    <h2>Conclusions</h2>
    <p class="instruction-text">[Replace with conclusions: Summarize achievements, lessons learned, challenges overcome, and potential future improvements.]</p>
   
    <h3>Key Achievements</h3>
    <p class="instruction-text">[List major accomplishments and successful design outcomes.]</p>
     <p>Our team successfully designed and verified a fully functional RISC-V based System-on-Chip (SoC) integrating a custom CPU core, AHB/APB bus interconnect, instruction and data memories, and a rich set of peripheral modules including UART, SPI, I²C, GPIO, LCD, timers, finite-state machines, and a full scan chain architecture. We implemented a complete end-to-end ASIC design flow, from architectural design, RTL implementation, and verification to synthesis, physical design, and tape-out, resolving all timing violations and achieving clean DRC/LVS signoff. To support software development, we built a customized RISC-V toolchain, linker script, and utilities tailored for a Harvard memory architecture. A comprehensive test suite, covering arithmetic kernels, peripheral interactions, metastability tests, and multiple demonstration programs, was developed and validated across both RTL and post-synthesis gate-level simulations. We also integrated deterministic scan-chain–based loading and run-mode execution for robust software-driven testing. Full post-route timing analysis and signoff were completed using Innovus, Virtuoso, and PrimeTime, culminating in the generation of the final GDSII and all required collateral for fabrication. After silicon returned, we performed post-silicon validation, designed a custom PCB for bring-up, and developed multiple demo applications to showcase the chip’s full functionality running on real hardware.
    </p>
    <h3>Lessons Learned</h3>
    <p class="instruction-text">[Discuss important insights gained during the design process.]</p>
    <p>Throughout the design and implementation of the SoC, we gained several important insights that shaped our engineering workflow. Managing a hierarchical SoC design requires careful planning of module interfaces, timing constraints, and verification strategies to ensure smooth integration and to prevent late-stage system-level issues. We found that addressing toolchain setup, linker configuration, and memory mapping early in the project greatly simplified software debugging and hardware bring-up. From a physical design standpoint, we learned that hold-time violations frequently emerge after synthesis and must be handled systematically during place-and-route through delay insertion and routing optimization. Additionally, macro placement, power grid design, and clock tree architecture proved to have substantial impact on timing closure, congestion, and overall chip robustness. Building a comprehensive testing framework—including both RTL and gate-level simulations—was essential to uncovering subtle timing and functional issues long before tape-out.</p>
    <p>After tape-out, we further learned the importance of planning for post-silicon validation, including designing accessible scan-chain hooks, preparing diagnostic firmware, and building modular test infrastructure. The bring-up process highlighted the value of well-organized PCB design, clear pin documentation, and flexible debugging utilities to quickly isolate hardware or software faults. Finally, developing real demo applications on the fabricated chip reinforced the need for strong coordination between hardware, firmware, and system validation, demonstrating that successful silicon requires not only correct design, but also thoughtful preparation for real-world testing and integration.</p>
    <h3>Future Work</h3>
    <p class="instruction-text">[Describe potential enhancements and next-generation features.]</p>
    <p>Looking ahead, several enhancements could significantly elevate the capability and performance of the next-generation SoC. CPU performance can be further improved through deeper pipeline optimization, more sophisticated branch prediction mechanisms, and enhanced ALU functionality. On the system level, integrating advanced peripherals such as DMA controllers, interrupt subsystems, or dedicated hardware accelerators for graphics or AI workloads would greatly expand the chip’s versatility. Power efficiency could be improved by introducing power-domain partitioning, fine-grained clock gating, and other low-power design techniques. From a tooling perspective, extending the software toolchain to support richer debugging features—such as on-chip breakpoints, real-time trace modules, or a full JTAG interface—would streamline firmware development and hardware bring-up. For physical design scalability, migrating to a more advanced technology node or increasing metal-layer count would enable higher operating frequencies and denser integration. Ultimately, these improvements could contribute to a second-generation SoC featuring larger on-chip memory, higher-speed interfaces, and greater interconnect bandwidth to support more complex real-world applications.</p>
  </section>
  
  <section id="references">
    <h2>References</h2>
    <p class="instruction-text">[Replace with references: List academic papers, technical manuals, and other resources cited in your project.]</p>
    <ol style="margin-left: 25px; color: var(--text-gray);">
      <li style="margin-bottom: 12px;"> Refenrence 1: https://docs.openhwgroup.org/projects/cv32e40p-user-manual/en/latest/intro.html</li>
      <li style="margin-bottom: 12px;"> Reference 2: https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://documentation-service.arm.com/static/63fe2c1356ea36189d4e79f3%3Ftoken%3D&ved=2ahUKEwiL-or6lKeRAxVPFVkFHbZNCjIQFnoECCMQAQ&usg=AOvVaw2XkJhpaIeA4ry31JCjoQdq</li>
      <li style="margin-bottom: 12px;">[Reference 3: Author, Title, Publication, Year]</li>
    </ol>
  </section>
  
  <section id="acknowledgments">
    <h2>Acknowledgments</h2>
    <p class="instruction-text">[Replace with acknowledgments: Thank advisors, sponsors, lab staff, and others who contributed to the project.]</p>
    
    <h3>Team Members</h3>
    <div class="team-grid">
      <div class="team-member">
      <strong>
      <a href="https://www.linkedin.com/in/m-lippe" target="_blank">Michael Lippe</a>
      </strong>
      <span>[Role/Contribution]</span>
      <span>ml5201@columbia.edu</span>
      </div>

      <div class="team-member">
      <strong>
      <a href="https://www.linkedin.com/in/qianxufu/" target="_blank">Qianxu Fu</a>
      </strong>
      <span>[Role/Contribution]</span>
      <span>qf2181@columbia.edu</span>
      </div>

      <div class="team-member">
      <strong>
      <a href="https://www.linkedin.com/in/bhargav-sriram-4ba537203/" target="_blank">Bhargav Sriram</a>
      </strong>
      <span>[Role/Contribution]</span>
      <span>bs3586@columbia.edu</span>
      </div>

      <div class="team-member">
      <strong>
      <a>Hongrui Huang</a>
      </strong>
      <span>[Role/Contribution]</span>
      <span>hh3084@columbia.edu</span>
      </div>

      <div class="team-member">
      <strong>
      <a>Hiroki Endo</a>
      </strong>
      <span>[Role/Contribution]</span>
      <span>he2305@columbia.edu</span>
      </div>

      <div class="team-member">
      <strong>
      <a>Yuan Jiang</a>
      </strong>
      <span>[Role/Contribution]</span>
      <span>yj2848@columbia.edu</span>
      </div>

      <div class="team-member">
      <strong>
      <a>Jingyi Lai</a>
      </strong>
      <span>[Role/Contribution]</span>
      <span>jl6932@columbia.edu</span>
      </div>
  </section>
  
  <a class="back" href="../index.html">Back to all projects</a>
</div>

<footer>
  <p>EE6350 VLSI Design Lab · Department of Electrical Engineering · Columbia University</p>
  <p style="margin-top: 8px; font-size: 0.9em; opacity: 0.8;">Spring 2025</p>
</footer>
</body>
</html>
